{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Data Exploration and Analysis -- 2013/2014 CitiBike-NYC Data\n",
    "**Michael Smith, Alex Frye, Chris Boomhower ----- 1/29/2017**\n",
    "\n",
    "<img src=\"Citi-Bike.jpg\" width=\"400\">\n",
    "<center>Image courtesy of http://newyorkeronthetown.com/, 2017</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "***Describe the purpose of the data set you selected***\n",
    "\n",
    "The data set selected by our group for this lab primarily consists of [Citi Bike trip history](https://www.citibikenyc.com/system-data) collected and released by NYC Bike Share, LLC and Jersey Bike Share, LLC under Citi Bike's [NYCBS Data Use Policy](https://www.citibikenyc.com/data-sharing-policy). Citi Bike is America's largest bike share program, with 10,000 bikes and 600 stations across Manhattan, Brooklyn, Queens, and Jersey City... 55 neighborhoods in all. As such, our data set's trip history includes all rental transactions conducted within the NYC Citi Bike system from July 1st, 2013 to February 28th, 2014. These transactions amount to <span style=\"color:red\">*####*</span> trips within this time frame. The original data set includes 15 attributes. That being said, our team was able to derive <span style=\"color:red\">*####*</span> more attributes from the original 15 as disussed in detail in the next section. Of particular note, however, we merged NYC weather data from the [Carbon Dioxide Information Analysis Center (CDIAC)](http://cdiac.ornl.gov/cgi-bin/broker?_PROGRAM=prog.climsite_daily.sas&_SERVICE=default&id=305801&_DEBUG=0) with the Citi Bike data to provide environmental insights into rental behavior as well.\n",
    "\n",
    "The trip data was collected via Citi Bike's check-in/check-out system among <span style=\"color:red\">*####*</span> of its stations in the NYC system as part of its transaction history log. While the non-publicized data likely includes further particulars such as rider payment details, the publicized data is anonymized to protect rider identity while simultaneously offering bike share transportation insights to urban developers, engineers, academics, statisticians, and other interested parties. The CDIAC data, however, was collected by the Department of Energy's Oak Ridge National Laboratory for research into global climate change. While basic weather conditions are recorded by CDIAC, as included in our fully merged data set, the organization also measures atmospheric carbon dioxide and other radiatively active gas levels to conduct their research efforts.\n",
    "\n",
    "Our team has taken particular interest in this data set as some of our team members enjoy both recreational and commute cycling. By combining basic weather data with Citi Bike's trip data, we expect to be able to predict whether riders are more likely to be (or become) Citi Bike subscribers based on ride environmental conditions, the day of the week for his/her trip, trip start and end locations, the general time of day (i.e. morning, midday, afternoon, evening, night) of his/her trip, his/her age and gender, etc. Deeper analysis may even yield further insights, such as identifying gaps in station location, for example. Furthermore, quantifiable predictions such as a rider's age as a function of trip distance and duration given other factors would provide improved targeting to bike share marketing efforts in New York City. Likewise, trip duration could be predicted based on other attributes which would allow the company to promote recreational cycling via factor adjustments within its control. By leveraging some of the vast number of trip observations as training data and others as test data via randomized selection, we expect to be able to measure the effectiveness of our algorithms and models throughout the semester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "***Describe the meaning and type of data***\n",
    "\n",
    "..Written response..\n",
    "\n",
    "*First discuss the care needed to utilize this data set in a non-time-series fashion*\n",
    "\n",
    "While attributes such as trip duration, start and end stations, bike ID, and basic rider details were collected and shared with the general public, care has been taken by Citi Bike to remove "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling Multiple Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from geopy.distance import vincenty\n",
    "import holidays\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-26 00:42:50.716567\n",
      "Found the File!\n",
      "RunTime: \n",
      "0:00:00.001501\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.now()\n",
    "print(starttime)\n",
    "\n",
    "if os.path.isfile(\"Compiled Data/dataset1.csv\"):\n",
    "    print(\"Found the File!\")\n",
    "else:\n",
    "    citiBikeDataDirectory = \"Citi Bike Data\"\n",
    "    citiBikeDataFileNames =[\n",
    "        \"2013-07 - Citi Bike trip data - 1.csv\",\n",
    "        \"2013-07 - Citi Bike trip data - 2.csv\",\n",
    "        \"2013-08 - Citi Bike trip data - 1.csv\",\n",
    "        \"2013-08 - Citi Bike trip data - 2.csv\",\n",
    "        \"2013-09 - Citi Bike trip data - 1.csv\",\n",
    "        \"2013-09 - Citi Bike trip data - 2.csv\",\n",
    "        \"2013-10 - Citi Bike trip data - 1.csv\",\n",
    "        \"2013-10 - Citi Bike trip data - 2.csv\",\n",
    "        \"2013-11 - Citi Bike trip data - 1.csv\",\n",
    "        \"2013-11 - Citi Bike trip data - 2.csv\",\n",
    "        \"2013-12 - Citi Bike trip data.csv\",\n",
    "        \"2014-01 - Citi Bike trip data.csv\",\n",
    "        \"2014-02 - Citi Bike trip data.csv\"\n",
    "    ]\n",
    "\n",
    "    weatherDataFile = \"Weather Data/NY305801_9255_edited.txt\"\n",
    "\n",
    "    citiBikeDataRaw = []\n",
    "\n",
    "    for file in citiBikeDataFileNames:\n",
    "        print(file)\n",
    "        filepath = citiBikeDataDirectory + \"/\" + file\n",
    "        with open(filepath) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            lines.pop(0)  # get rid of the first line that contains the column names\n",
    "            for line in lines:\n",
    "                line = line.replace('\"', '')\n",
    "                line = line.split(\",\")\n",
    "                sLatLong = (line[5], line[6])\n",
    "                eLatLong = (line[9], line[10])\n",
    "\n",
    "                distance = vincenty(sLatLong, eLatLong).miles\n",
    "                line.extend([distance])\n",
    "\n",
    "                ## Monday       = 0\n",
    "                ## Tuesday      = 1\n",
    "                ## Wednesday    = 2\n",
    "                ## Thursday     = 3\n",
    "                ## Friday       = 4\n",
    "                ## Saturday     = 5\n",
    "                ## Sunday       = 6\n",
    "                if parse(line[1]).weekday() == 0:\n",
    "                    DayOfWeek = \"Monday\"\n",
    "                elif parse(line[1]).weekday() == 1:\n",
    "                    DayOfWeek = \"Tuesday\"\n",
    "                elif parse(line[1]).weekday() == 2:\n",
    "                    DayOfWeek = \"Wednesday\"\n",
    "                elif parse(line[1]).weekday() == 3:\n",
    "                    DayOfWeek = \"Thursday\"\n",
    "                elif parse(line[1]).weekday() == 4:\n",
    "                    DayOfWeek = \"Friday\"\n",
    "                elif parse(line[1]).weekday() == 5:\n",
    "                    DayOfWeek = \"Saturday\"\n",
    "                else:\n",
    "                    DayOfWeek = \"Sunday\"\n",
    "                line.extend([DayOfWeek])\n",
    "\n",
    "                ##Morning       5AM-10AM\n",
    "                ##Midday        10AM-2PM\n",
    "                ##Afternoon     2PM-5PM\n",
    "                ##Evening       5PM-10PM\n",
    "                ##Night         10PM-5AM\n",
    "\n",
    "                if parse(line[1]).hour >= 5 and parse(line[1]).hour < 10:\n",
    "                    TimeOfDay = 'Morning'\n",
    "                elif parse(line[1]).hour >= 10 and parse(line[1]).hour < 14:\n",
    "                    TimeOfDay = 'Midday'\n",
    "                elif parse(line[1]).hour >= 14 and parse(line[1]).hour < 17:\n",
    "                    TimeOfDay = 'Afternoon'\n",
    "                elif parse(line[1]).hour >= 17 and parse(line[1]).hour < 22:\n",
    "                    TimeOfDay = 'Evening'\n",
    "                else:\n",
    "                    TimeOfDay = 'Night'\n",
    "                line.extend([TimeOfDay])\n",
    "\n",
    "                ## 1 = Yes\n",
    "                ## 0 = No\n",
    "                if parse(line[1]) in holidays.UnitedStates():\n",
    "                    holidayFlag = \"1\"\n",
    "                else:\n",
    "                    holidayFlag = \"0\"\n",
    "                line.extend([holidayFlag])\n",
    "\n",
    "                citiBikeDataRaw.append(line)\n",
    "            del lines\n",
    "\n",
    "    with open(weatherDataFile) as f:\n",
    "        weatherDataRaw = f.read().splitlines()\n",
    "        weatherDataRaw.pop(0)  # again, get rid of the column names\n",
    "        for c in range(len(weatherDataRaw)):\n",
    "            weatherDataRaw[c] = weatherDataRaw[c].split(\",\")\n",
    "            # Adjust days and months to have a leading zero so we can capture all the data\n",
    "            if len(weatherDataRaw[c][2]) < 2:\n",
    "                weatherDataRaw[c][2] = \"0\" + weatherDataRaw[c][2]\n",
    "            if len(weatherDataRaw[c][0]) < 2:\n",
    "                weatherDataRaw[c][0] = \"0\" + weatherDataRaw[c][0]\n",
    "\n",
    "    citiBikeData = []\n",
    "\n",
    "    while (citiBikeDataRaw):\n",
    "        instance = citiBikeDataRaw.pop()\n",
    "        date = instance[1].split(\" \")[0].split(\"-\")  # uses the start date of the loan\n",
    "        for record in weatherDataRaw:\n",
    "            if (str(date[0]) == str(record[4]) and str(date[1]) == str(record[2]) and str(date[2]) == str(record[0])):\n",
    "                instance.extend([record[5], record[6], record[7], record[8], record[9]])\n",
    "                citiBikeData.append(instance)\n",
    "\n",
    "    del citiBikeDataRaw\n",
    "    del weatherDataRaw\n",
    "\n",
    "    # Final Columns:\n",
    "    #  0 tripduration\n",
    "    #  1 starttime\n",
    "    #  2 stoptime\n",
    "    #  3 start station id\n",
    "    #  4 start station name\n",
    "    #  5 start station latitude\n",
    "    #  6 start station longitude\n",
    "    #  7 end station id\n",
    "    #  8 end station name\n",
    "    #  9 end station latitude\n",
    "    # 10 end station longitude\n",
    "    # 11 bikeid\n",
    "    # 12 usertype\n",
    "    # 13 birth year\n",
    "    # 14 gender\n",
    "    # 15 start/end station distance\n",
    "    # 16 DayOfWeek\n",
    "    # 17 TimeOfDay\n",
    "    # 18 HolidayFlag\n",
    "    # 19 PRCP\n",
    "    # 20 SNOW\n",
    "    # 21 TAVE\n",
    "    # 22 TMAX\n",
    "    # 23 TMIN\n",
    "\n",
    "    maxLineCount = 250000\n",
    "    lineCounter = 1\n",
    "    fileCounter = 1\n",
    "    outputDirectoryFilename = \"Compiled Data/dataset\"\n",
    "    f = open(outputDirectoryFilename + str(fileCounter) + \".csv\", \"w\")\n",
    "    for line in citiBikeData:\n",
    "        if lineCounter == 250000:\n",
    "            print(f)\n",
    "            f.close()\n",
    "            lineCounter = 1\n",
    "            fileCounter = fileCounter + 1\n",
    "            f = open(outputDirectoryFilename + str(fileCounter) + \".csv\", \"w\")\n",
    "        f.write(\",\".join(map(str, line)) + \"\\n\")\n",
    "        lineCounter = lineCounter + 1\n",
    "\n",
    "    del citiBikeData\n",
    "        \n",
    "endtime = datetime.now()\n",
    "print(\"RunTime: \")\n",
    "print(endtime-starttime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Loading the Compiled Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "   tripduration           starttime            stoptime  start_station_id  \\\n",
      "0           308 2014-02-28 23:59:10 2014-03-01 00:04:18               353   \n",
      "1           304 2014-02-28 23:58:17 2014-03-01 00:03:21               497   \n",
      "2          1355 2014-02-28 23:57:55 2014-03-01 00:20:30               470   \n",
      "3           848 2014-02-28 23:57:13 2014-03-01 00:11:21               498   \n",
      "4           175 2014-02-28 23:57:12 2014-03-01 00:00:07               383   \n",
      "\n",
      "           start_station_name  start_station_latitude  \\\n",
      "0  S Portland Ave & Hanson Pl               40.685396   \n",
      "1          E 17 St & Broadway               40.737050   \n",
      "2             W 20 St & 8 Ave               40.743453   \n",
      "3          Broadway & W 32 St               40.748549   \n",
      "4  Greenwich Ave & Charles St               40.735238   \n",
      "\n",
      "   start_station_longitude  end_station_id       end_station_name  \\\n",
      "0               -73.974315             365  Fulton St & Grand Ave   \n",
      "1               -73.990093             334        W 20 St & 7 Ave   \n",
      "2               -74.000040             302      Avenue D & E 3 St   \n",
      "3               -73.988084             432      E 7 St & Avenue A   \n",
      "4               -74.000271             284  Greenwich Ave & 8 Ave   \n",
      "\n",
      "   end_station_latitude ...   LinearDistance  DayOfWeek TimeOfDay  \\\n",
      "0             40.682232 ...         0.709731     Friday     Night   \n",
      "1             40.742388 ...         0.526555     Friday     Night   \n",
      "2             40.720828 ...         1.945255     Friday     Night   \n",
      "3             40.726218 ...         1.557209     Friday     Night   \n",
      "4             40.739017 ...         0.288829     Friday     Night   \n",
      "\n",
      "   HolidayFlag  PRCP  SNOW TAVE TMAX  TMIN  Age  \n",
      "0            0   0.0   0.0   17   24     9   32  \n",
      "1            0   0.0   0.0   17   24     9   46  \n",
      "2            0   0.0   0.0   17   24     9   29  \n",
      "3            0   0.0   0.0   17   24     9   38  \n",
      "4            0   0.0   0.0   17   24     9   58  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "def reader(f, columns):\n",
    "    d = pd.read_csv(f)\n",
    "    d.columns = columns\n",
    "    return d\n",
    "\n",
    "\n",
    "path = r'Compiled Data'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "columns = [\"tripduration\", \"starttime\", \"stoptime\", \"start_station_id\", \"start_station_name\", \"start_station_latitude\",\n",
    "           \"start_station_longitude\", \"end_station_id\", \"end_station_name\", \"end_station_latitude\",\n",
    "           \"end_station_longitude\", \"bikeid\", \"usertype\", \"birth year\", \"gender\", \"LinearDistance\", \"DayOfWeek\",\n",
    "           \"TimeOfDay\", \"HolidayFlag\", \"PRCP\", \"SNOW\", \"TAVE\", \"TMAX\", \"TMIN\"]\n",
    "\n",
    "CitiBikeDataCompiled = pd.concat([reader(f, columns) for f in all_files])\n",
    "\n",
    "    #Replace '\\N' Birth Years with Zero Values\n",
    "CitiBikeDataCompiled[\"birth year\"] = CitiBikeDataCompiled[\"birth year\"].replace(r'\\N','0')\n",
    "\n",
    "# Convert Columns to Numerical Values\n",
    "CitiBikeDataCompiled[['tripduration', 'bikeid', 'birth year', 'LinearDistance','PRCP', 'SNOW', 'TAVE', 'TMAX', 'TMIN']]\\\n",
    "    = CitiBikeDataCompiled[['tripduration', 'bikeid', 'birth year','LinearDistance', 'PRCP', 'SNOW', 'TAVE', 'TMAX',\n",
    "                            'TMIN']].apply(pd.to_numeric)\n",
    "\n",
    "# Convert Columns to Date Values\n",
    "CitiBikeDataCompiled[['starttime', 'stoptime']] \\\n",
    "    = CitiBikeDataCompiled[['starttime', 'stoptime']].apply(pd.to_datetime)\n",
    "\n",
    "    ## Compute Age: 0 Birth Year = 0 Age ELSE Compute Start Time Year Minus Birth Year\n",
    "CitiBikeDataCompiled[\"Age\"] = np.where(CitiBikeDataCompiled[\"birth year\"]==0, 0,\n",
    "                                       CitiBikeDataCompiled[\"starttime\"].dt.year - CitiBikeDataCompiled[\"birth year\"])\n",
    "\n",
    "print(CitiBikeDataCompiled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality\n",
    "\n",
    "two attributes with large quantity of missing values: birth year, gender as this is optional information for non-subscribing customers. build plot for missing value count by user type to show this. Gender is already defaulted at \"0\" for not provided; we have defaulted our NAs to 0 for birth year and will need to account for these missing values cautiously in our models moving forward.\n",
    "\n",
    "no duplicates\n",
    "\n",
    "Discuss our computed distance, and how it may not accurately represent the \"actual\" trip the biker took. we do not have enough information to more accurately compute this distance  \n",
    "\n",
    "search for outlier duration times small and large; outlier distances; age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize appropriate statistics\n",
    "\n",
    "- provide panda .describe output and interpret\n",
    " \n",
    "- group data by trip start and end, identify variance in trip durations for the same route. do we trust our distance calc?\n",
    "\n",
    "- distribution of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "      <th>LinearDistance</th>\n",
       "      <th>HolidayFlag</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TAVE</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "      <td>5.562293e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.788105e+02</td>\n",
       "      <td>4.392880e+02</td>\n",
       "      <td>4.073437e+01</td>\n",
       "      <td>-7.399097e+01</td>\n",
       "      <td>4.396748e+02</td>\n",
       "      <td>4.073407e+01</td>\n",
       "      <td>-7.399108e+01</td>\n",
       "      <td>1.768373e+04</td>\n",
       "      <td>1.733736e+03</td>\n",
       "      <td>1.081256e+00</td>\n",
       "      <td>1.121726e+00</td>\n",
       "      <td>2.460101e-02</td>\n",
       "      <td>6.233738e-02</td>\n",
       "      <td>3.806081e-02</td>\n",
       "      <td>6.169050e+01</td>\n",
       "      <td>6.851392e+01</td>\n",
       "      <td>5.437925e+01</td>\n",
       "      <td>3.296077e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.996950e+03</td>\n",
       "      <td>3.418623e+02</td>\n",
       "      <td>1.985896e-02</td>\n",
       "      <td>1.237109e-02</td>\n",
       "      <td>3.467747e+02</td>\n",
       "      <td>1.987918e-02</td>\n",
       "      <td>1.246342e-02</td>\n",
       "      <td>1.761230e+03</td>\n",
       "      <td>6.475671e+02</td>\n",
       "      <td>5.653095e-01</td>\n",
       "      <td>8.459473e-01</td>\n",
       "      <td>1.549058e-01</td>\n",
       "      <td>2.016957e-01</td>\n",
       "      <td>4.336314e-01</td>\n",
       "      <td>1.675271e+01</td>\n",
       "      <td>1.730100e+01</td>\n",
       "      <td>1.647196e+01</td>\n",
       "      <td>1.609177e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>4.068034e+01</td>\n",
       "      <td>-7.401713e+01</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>4.068034e+01</td>\n",
       "      <td>-7.401713e+01</td>\n",
       "      <td>1.452900e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.980000e+02</td>\n",
       "      <td>3.040000e+02</td>\n",
       "      <td>4.072066e+01</td>\n",
       "      <td>-7.400004e+01</td>\n",
       "      <td>3.030000e+02</td>\n",
       "      <td>4.072043e+01</td>\n",
       "      <td>-7.400026e+01</td>\n",
       "      <td>1.616700e+04</td>\n",
       "      <td>1.963000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.357136e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>5.600000e+01</td>\n",
       "      <td>4.300000e+01</td>\n",
       "      <td>2.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.340000e+02</td>\n",
       "      <td>4.030000e+02</td>\n",
       "      <td>4.073625e+01</td>\n",
       "      <td>-7.399076e+01</td>\n",
       "      <td>4.020000e+02</td>\n",
       "      <td>4.073544e+01</td>\n",
       "      <td>-7.399076e+01</td>\n",
       "      <td>1.768200e+04</td>\n",
       "      <td>1.976000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.846575e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>7.300000e+01</td>\n",
       "      <td>5.700000e+01</td>\n",
       "      <td>3.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.042000e+03</td>\n",
       "      <td>4.860000e+02</td>\n",
       "      <td>4.075020e+01</td>\n",
       "      <td>-7.398195e+01</td>\n",
       "      <td>4.840000e+02</td>\n",
       "      <td>4.074972e+01</td>\n",
       "      <td>-7.398195e+01</td>\n",
       "      <td>1.917700e+04</td>\n",
       "      <td>1.983000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.465782e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.500000e+01</td>\n",
       "      <td>8.200000e+01</td>\n",
       "      <td>6.800000e+01</td>\n",
       "      <td>4.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.250750e+06</td>\n",
       "      <td>3.002000e+03</td>\n",
       "      <td>4.077051e+01</td>\n",
       "      <td>-7.395005e+01</td>\n",
       "      <td>3.002000e+03</td>\n",
       "      <td>4.077051e+01</td>\n",
       "      <td>-7.395005e+01</td>\n",
       "      <td>2.154200e+04</td>\n",
       "      <td>1.997000e+03</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>6.491681e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.980000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>9.000000e+01</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>1.150000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tripduration  start_station_id  start_station_latitude  \\\n",
       "count  5.562293e+06      5.562293e+06            5.562293e+06   \n",
       "mean   8.788105e+02      4.392880e+02            4.073437e+01   \n",
       "std    3.996950e+03      3.418623e+02            1.985896e-02   \n",
       "min    6.000000e+01      7.200000e+01            4.068034e+01   \n",
       "25%    3.980000e+02      3.040000e+02            4.072066e+01   \n",
       "50%    6.340000e+02      4.030000e+02            4.073625e+01   \n",
       "75%    1.042000e+03      4.860000e+02            4.075020e+01   \n",
       "max    6.250750e+06      3.002000e+03            4.077051e+01   \n",
       "\n",
       "       start_station_longitude  end_station_id  end_station_latitude  \\\n",
       "count             5.562293e+06    5.562293e+06          5.562293e+06   \n",
       "mean             -7.399097e+01    4.396748e+02          4.073407e+01   \n",
       "std               1.237109e-02    3.467747e+02          1.987918e-02   \n",
       "min              -7.401713e+01    7.200000e+01          4.068034e+01   \n",
       "25%              -7.400004e+01    3.030000e+02          4.072043e+01   \n",
       "50%              -7.399076e+01    4.020000e+02          4.073544e+01   \n",
       "75%              -7.398195e+01    4.840000e+02          4.074972e+01   \n",
       "max              -7.395005e+01    3.002000e+03          4.077051e+01   \n",
       "\n",
       "       end_station_longitude        bikeid    birth year        gender  \\\n",
       "count           5.562293e+06  5.562293e+06  5.562293e+06  5.562293e+06   \n",
       "mean           -7.399108e+01  1.768373e+04  1.733736e+03  1.081256e+00   \n",
       "std             1.246342e-02  1.761230e+03  6.475671e+02  5.653095e-01   \n",
       "min            -7.401713e+01  1.452900e+04  0.000000e+00  0.000000e+00   \n",
       "25%            -7.400026e+01  1.616700e+04  1.963000e+03  1.000000e+00   \n",
       "50%            -7.399076e+01  1.768200e+04  1.976000e+03  1.000000e+00   \n",
       "75%            -7.398195e+01  1.917700e+04  1.983000e+03  1.000000e+00   \n",
       "max            -7.395005e+01  2.154200e+04  1.997000e+03  2.000000e+00   \n",
       "\n",
       "       LinearDistance   HolidayFlag          PRCP          SNOW          TAVE  \\\n",
       "count    5.562293e+06  5.562293e+06  5.562293e+06  5.562293e+06  5.562293e+06   \n",
       "mean     1.121726e+00  2.460101e-02  6.233738e-02  3.806081e-02  6.169050e+01   \n",
       "std      8.459473e-01  1.549058e-01  2.016957e-01  4.336314e-01  1.675271e+01   \n",
       "min      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  1.100000e+01   \n",
       "25%      5.357136e-01  0.000000e+00  0.000000e+00  0.000000e+00  5.000000e+01   \n",
       "50%      8.846575e-01  0.000000e+00  0.000000e+00  0.000000e+00  6.500000e+01   \n",
       "75%      1.465782e+00  0.000000e+00  1.000000e-02  0.000000e+00  7.500000e+01   \n",
       "max      6.491681e+00  1.000000e+00  1.980000e+00  1.100000e+01  9.000000e+01   \n",
       "\n",
       "               TMAX          TMIN           Age  \n",
       "count  5.562293e+06  5.562293e+06  5.562293e+06  \n",
       "mean   6.851392e+01  5.437925e+01  3.296077e+01  \n",
       "std    1.730100e+01  1.647196e+01  1.609177e+01  \n",
       "min    1.700000e+01  4.000000e+00  0.000000e+00  \n",
       "25%    5.600000e+01  4.300000e+01  2.600000e+01  \n",
       "50%    7.300000e+01  5.700000e+01  3.300000e+01  \n",
       "75%    8.200000e+01  6.800000e+01  4.300000e+01  \n",
       "max    9.800000e+01  8.300000e+01  1.150000e+02  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CitiBikeDataCompiled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Interesting Attributes\n",
    "\n",
    "- Trip Duration by day of week [Boxplot]\n",
    "\n",
    "- Average Trip linear distance by day of week [Boxplot]\n",
    "\n",
    "- Average Trip duration by start time of day (evening, morning, etc.)[Boxplot]\n",
    "\n",
    "- Holidays with the largest bike traffic avg holiday compared to avg non holiday [Barchart]\n",
    "\n",
    "- percentage of bike users that are subscribers vs non-subscribers [pie]\n",
    "\n",
    "- age group / gender by avg trip duration [barplot] (note in interpretation to discuss missing values for nonsubscribing members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Relationships Between Attributes\n",
    "\n",
    "- [Parallel coordinate plot] (y - inches; x = weather types; day of week = colors)\n",
    "- Identify if there is correlation between bike id , frequency of trip, and duration of trip. (does a lower bike id represent an older bike, therefore worse condition causing shorter trips) [corr scatterplot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Relationships Between Features and Prediction Class\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features That Could Be Added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptional Work\n",
    "\n",
    "Exceptional Visualizations\n",
    "- Weather Map + Density vector for number of active bikers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
