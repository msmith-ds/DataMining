{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Data Exploration and Analysis -- 2013/2014 CitiBike-NYC Data\n",
    "**Michael Smith, Alex Frye, Chris Boomhower ----- 1/29/2017**\n",
    "\n",
    "<img src=\"https://github.com/msmith-ds/DataMining/blob/master/Project1/Images/Citi-Bike.jpg?raw=true\" width=\"400\">\n",
    "\n",
    "<center>Image courtesy of http://newyorkeronthetown.com/, 2017</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "***Describe the purpose of the data set you selected***\n",
    "\n",
    "The data set selected by our group for this lab primarily consists of [Citi Bike trip history](https://www.citibikenyc.com/system-data) collected and released by NYC Bike Share, LLC and Jersey Bike Share, LLC under Citi Bike's [NYCBS Data Use Policy](https://www.citibikenyc.com/data-sharing-policy). Citi Bike is America's largest bike share program, with 10,000 bikes and 600 stations across Manhattan, Brooklyn, Queens, and Jersey City... 55 neighborhoods in all. As such, our data set's trip history includes all rental transactions conducted within the NYC Citi Bike system from July 1st, 2013 to February 28th, 2014. These transactions amount to 5562293 trips within this time frame. The original data set includes 15 attributes. That being said, our team was able to derive 15 more attributes from the original 15 as disussed in detail in the next section. Of particular note, however, we merged NYC weather data from the [Carbon Dioxide Information Analysis Center (CDIAC)](http://cdiac.ornl.gov/cgi-bin/broker?_PROGRAM=prog.climsite_daily.sas&_SERVICE=default&id=305801&_DEBUG=0) with the Citi Bike data to provide environmental insights into rental behavior as well.\n",
    "\n",
    "The trip data was collected via Citi Bike's check-in/check-out system among 330 of its stations in the NYC system as part of its transaction history log. While the non-publicized data likely includes further particulars such as rider payment details, the publicized data is anonymized to protect rider identity while simultaneously offering bike share transportation insights to urban developers, engineers, academics, statisticians, and other interested parties. The CDIAC data, however, was collected by the Department of Energy's Oak Ridge National Laboratory for research into global climate change. While basic weather conditions are recorded by CDIAC, as included in our fully merged data set, the organization also measures atmospheric carbon dioxide and other radiatively active gas levels to conduct their research efforts.\n",
    "\n",
    "Our team has taken particular interest in this data set as some of our team members enjoy both recreational and commute cycling. By combining basic weather data with Citi Bike's trip data, we expect to be able to predict whether riders are more likely to be (or become) Citi Bike subscribers based on ride environmental conditions, the day of the week for his/her trip, trip start and end locations, the general time of day (i.e. morning, midday, afternoon, evening, night) of his/her trip, his/her age and gender, etc. Deeper analysis may even yield further insights, such as identifying gaps in station location, for example. Furthermore, quantifiable predictions such as a rider's age as a function of trip distance and duration given other factors would provide improved targeting to bike share marketing efforts in New York City. Likewise, trip duration could be predicted based on other attributes which would allow the company to promote recreational cycling via factor adjustments within its control. By leveraging some of the vast number of trip observations as training data and others as test data via randomized selection, we expect to be able to measure the effectiveness of our algorithms and models throughout the semester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "***Describe the meaning and type of data***\n",
    "\n",
    "Before diving into each attribute in detail, one glaring facet of this data set that needs mentioning is its inherent time-series nature. By no means was this overlooked when we decided upon these particular data. To mitigate the effects of time on our analysis results, we have chosen to aggregate time-centric attributes such as dates and hours of the day by replacing them with simply the day of the week or period of the day (more on these details shortly). For example, by identifying trips occurring on July 1st, 2013, not by the date of occurrence but rather the day of the week, Monday, and identifying trips on July 2nd, 2013, as occurring on Tuesday, we will be able to obtain a \"big picture\" understanding of trends by day of the week instead of at the date-by-date level. We understand this is not a perfect solution since the time-series component is still an underlying factor in trip activity, but it is good enough to answer the types of questions we hope to target as described in the previous section as we will be comparing all Mondays against all Tuesdays, etc.\n",
    "\n",
    "As mentioned previously, the original data set ***from Citi Bike*** included 15 attributes. These 15 attributes and associated descriptions are provided below:\n",
    "1. **tripduration** - *Integer* - The total time (in seconds) a bike remains checked out, beginning with the start time and ending with the stop time\n",
    "2. **starttime** - *DateTime* - The date and time at which a bike was checked out, marking the start of a trip (i.e. 2/12/2014 8:16)\n",
    "3. **stoptime** - *DateTime* - The date and time at which a bike was checked back in, marking the end of a trip (i.e. 2/12/2014 8:16)\n",
    "4. **start_station_id** - *String* - A categorical number value used to identify Citi Bike stations, in this case the station from which a bike is checked out\n",
    "5. **start_station_name** - *String* - The name of the station from which a bike is checked out; most often the name of an intersection (i.e. E 39 St & 2 Ave)\n",
    "6. **start_station_latitude** - *Float* - The latitude coordinate for the station from which a bike is checked out (i.e. 40.74780373)\n",
    "7. **start_station_longitude** - *Float* - The longitude coordinate for the station from which a bike is checked out (i.e. -73.9900262)\n",
    "8. **end_station_id** - *String* - A categorical number value used to identify Citi Bike stations, in this case the station in which a bike is checked in\n",
    "9. **end_station_name** - *String* - The name of the station at which a bike is checked in; most often the name of an intersection (i.e. E 39 St & 2 Ave)\n",
    "10. **end_station_latitude** - *Float* - The latitude coordinate for the station at which a bike is checked in (i.e. 40.74780373)\n",
    "11. **end_station_longitude** - *Float* - The longitude coordinate for the station at which a bike is checked in (i.e. -73.9900262)\n",
    "12. **bikeid** - *String* - A categorical number value used to identify a particular bike; each bike in the bike share network has its own unique number\n",
    "13. **usertype** - *String* - A classifier attribute identifying a rider as a bike share subscriber or a one-time customer (i.e. Subscriber vs. Customer)\n",
    "14. **birth_year** - *Integer* - The year a rider was born (Only available for subscribed riders, however)\n",
    "15. **gender** - *String* - A categorical number value representing a rider's gender (i.e. 0 = unknown, 1 = male, 2 = female)\n",
    "\n",
    "\n",
    "It is important to note that birth year and gender details are not available for \"Customer\" user types but rather for \"Subscriber\" riders only. Fortunately, these are the only missing data values among all trips in the data set. Unfortunately, however, it means that we will not be able to identify the ratio of males-to-females that are not subscribed or use age to predict subcribers vs. non-subscribers (Customers). More to this end will be discussed in the next section.\n",
    "\n",
    "It is also worth mentioning that while attributes such as trip duration, start and end stations, bike ID, and basic rider details were collected and shared with the general public, care was taken by Citi Bike to remove trips taken by staff during system service appointments and inspections, trips to or from \"test\" stations which were employed during the data set's timeframe, and trips lasting less than 60 seconds which could indicate false checkout or re-docking efforts during checkin.\n",
    "\n",
    "Because some attributes may be deemed as duplicates (i.e. start_station_id, start_station_name, and start_station_latitude/longitude for identifying station locations), we chose to extract further attributes from the base attributes at hand. Further attributes were also extracted to mitigate the effects of time. In addition, we felt increased understanding could be obtained from combining weather data for the various trips as discussed in the previous section. These additional 10 attributes are described below:\n",
    "\n",
    "16. **LinearDistance** - *Integer* - The distance (miles) from a start station to an end station (as a crow flies); calculated from the latitude/longitude coordinates of start/end stations\n",
    "17. **DayOfWeek** - *String* - The day of the week a trip occurs regardless of time of day, month, etc.; extracted from the *starttime* attribute (i.e. Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday)\n",
    "18. **TimeOfDay** - *String* - The portion of the day during which a bike was checked out; extracted from the *starttime* attribute (i.e. Morning, Midday, Afternoon, Evening, Night)\n",
    "19. **HolidayFlag** - *String* - A categorical binary value used to identify whether the day a trip occurred was on a holiday or not; extracted from the *starttime* attribute (i.e. 0 = Non-Holiday, 1 = Holiday)\n",
    "20. **Age** - *Integer* - The age of a rider at the time of a trip; calculated based on the *birth_year* attribute (Since only birth year is included in original Citi Bike data set, exact age at time of trip when considering birth month is not possible)\n",
    "21. **PRCP** - *Float* - The total recorded rainfall in inches on the day of a trip; merged from the CDIAC weather data set\n",
    "22. **SNOW** - *Float* - The total recorded snowfall in inches on the day of a trip; merged from the CDIAC weather data set\n",
    "23. **TAVE** - *Integer* - The average temperature throughout the day on which a trip occurs; merged from the CDIAC weather data set\n",
    "24. **TMAX** - *Integer* - The maximum temperature on the day on which a trip occurs; merged from the CDIAC weather data set\n",
    "25. **TMIN** - *Integer* - The minimum temperature on the day on which a trip occurs; merged from the CDIAC weather data set\n",
    "\n",
    "After extracting our own attributes and merging weather data, the total number of attributes present in our final data set is 25. Only 15 are used throughout this lab, however, due to the duplicate nature of some attributes as discussed already. This final list of ***used*** attributes are tripduration, DayOfWeek, TimeOfDay, HolidayFlag, start_station_name, start_station_latitude, start_station_longitude, usertype, gender, Age, PRCP, SNOW, TAVE, TMAX, and TMIN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compiling Multiple Data Sources\n",
    "\n",
    "To begin our analysis, we need to load the data from our source .csv files. Steps taken to pull data from the various source files are as follows:\n",
    "- For each file from CitiBike, we process each line appending manually computed columns [LinearDistance, DayOfWeek, TimeOfDay, & HolidayFlag]. \n",
    "- Similarly, we load our weather data .csv file.\n",
    "- With both source file variables gathered, we append the weather data to our CitiBike data by matching on the date.\n",
    "- To avoid a 2 hour run-time in our analysis every execution, we load the final version of the data into .CSV files. Each file consists of 250000 records to reduce file size for GitHub loads.\n",
    "- All above logic is skipped if the file \"Compiled Data/dataset1.csv\" already exists.\n",
    "\n",
    "Below you will see this process, as well as import/options for needed python modules throughout this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from geopy.distance import vincenty\n",
    "import holidays\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import gmaps\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import statistics\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "py.offline.init_notebook_mode()\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "starttime = datetime.now()\n",
    "print(starttime)\n",
    "\n",
    "if os.path.isfile(\"Compiled Data/dataset1.csv\"):\n",
    "    print(\"Found the File!\")\n",
    "else:\n",
    "    citiBikeDataDirectory = \"Citi Bike Data\"\n",
    "    citiBikeDataFileNames =[\n",
    "        \"2013-07 - Citi Bike trip data - 1.csv\",\n",
    "        \"2013-07 - Citi Bike trip data - 2.csv\",\n",
    "        \"2013-08 - Citi Bike trip data - 1.csv\",\n",
    "        \"2013-08 - Citi Bike trip data - 2.csv\",\n",
    "        \"2013-09 - Citi Bike trip data - 1.csv\",\n",
    "        \"2013-09 - Citi Bike trip data - 2.csv\",\n",
    "        \"2013-10 - Citi Bike trip data - 1.csv\",\n",
    "        \"2013-10 - Citi Bike trip data - 2.csv\",\n",
    "        \"2013-11 - Citi Bike trip data - 1.csv\",\n",
    "        \"2013-11 - Citi Bike trip data - 2.csv\",\n",
    "        \"2013-12 - Citi Bike trip data.csv\",\n",
    "        \"2014-01 - Citi Bike trip data.csv\",\n",
    "        \"2014-02 - Citi Bike trip data.csv\"\n",
    "    ]\n",
    "\n",
    "    weatherDataFile = \"Weather Data/NY305801_9255_edited.txt\"\n",
    "\n",
    "    citiBikeDataRaw = []\n",
    "\n",
    "    for file in citiBikeDataFileNames:\n",
    "        print(file)\n",
    "        filepath = citiBikeDataDirectory + \"/\" + file\n",
    "        with open(filepath) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            lines.pop(0)  # get rid of the first line that contains the column names\n",
    "            for line in lines:\n",
    "                line = line.replace('\"', '')\n",
    "                line = line.split(\",\")\n",
    "                sLatLong = (line[5], line[6])\n",
    "                eLatLong = (line[9], line[10])\n",
    "\n",
    "                distance = vincenty(sLatLong, eLatLong).miles\n",
    "                line.extend([distance])\n",
    "\n",
    "                ## Monday       = 0\n",
    "                ## Tuesday      = 1\n",
    "                ## Wednesday    = 2\n",
    "                ## Thursday     = 3\n",
    "                ## Friday       = 4\n",
    "                ## Saturday     = 5\n",
    "                ## Sunday       = 6\n",
    "                if parse(line[1]).weekday() == 0:\n",
    "                    DayOfWeek = \"Monday\"\n",
    "                elif parse(line[1]).weekday() == 1:\n",
    "                    DayOfWeek = \"Tuesday\"\n",
    "                elif parse(line[1]).weekday() == 2:\n",
    "                    DayOfWeek = \"Wednesday\"\n",
    "                elif parse(line[1]).weekday() == 3:\n",
    "                    DayOfWeek = \"Thursday\"\n",
    "                elif parse(line[1]).weekday() == 4:\n",
    "                    DayOfWeek = \"Friday\"\n",
    "                elif parse(line[1]).weekday() == 5:\n",
    "                    DayOfWeek = \"Saturday\"\n",
    "                else:\n",
    "                    DayOfWeek = \"Sunday\"\n",
    "                line.extend([DayOfWeek])\n",
    "\n",
    "                ##Morning       5AM-10AM\n",
    "                ##Midday        10AM-2PM\n",
    "                ##Afternoon     2PM-5PM\n",
    "                ##Evening       5PM-10PM\n",
    "                ##Night         10PM-5AM\n",
    "\n",
    "                if parse(line[1]).hour >= 5 and parse(line[1]).hour < 10:\n",
    "                    TimeOfDay = 'Morning'\n",
    "                elif parse(line[1]).hour >= 10 and parse(line[1]).hour < 14:\n",
    "                    TimeOfDay = 'Midday'\n",
    "                elif parse(line[1]).hour >= 14 and parse(line[1]).hour < 17:\n",
    "                    TimeOfDay = 'Afternoon'\n",
    "                elif parse(line[1]).hour >= 17 and parse(line[1]).hour < 22:\n",
    "                    TimeOfDay = 'Evening'\n",
    "                else:\n",
    "                    TimeOfDay = 'Night'\n",
    "                line.extend([TimeOfDay])\n",
    "\n",
    "                ## 1 = Yes\n",
    "                ## 0 = No\n",
    "                if parse(line[1]) in holidays.UnitedStates():\n",
    "                    holidayFlag = \"1\"\n",
    "                else:\n",
    "                    holidayFlag = \"0\"\n",
    "                line.extend([holidayFlag])\n",
    "\n",
    "                citiBikeDataRaw.append(line)\n",
    "            del lines\n",
    "\n",
    "    with open(weatherDataFile) as f:\n",
    "        weatherDataRaw = f.read().splitlines()\n",
    "        weatherDataRaw.pop(0)  # again, get rid of the column names\n",
    "        for c in range(len(weatherDataRaw)):\n",
    "            weatherDataRaw[c] = weatherDataRaw[c].split(\",\")\n",
    "            # Adjust days and months to have a leading zero so we can capture all the data\n",
    "            if len(weatherDataRaw[c][2]) < 2:\n",
    "                weatherDataRaw[c][2] = \"0\" + weatherDataRaw[c][2]\n",
    "            if len(weatherDataRaw[c][0]) < 2:\n",
    "                weatherDataRaw[c][0] = \"0\" + weatherDataRaw[c][0]\n",
    "\n",
    "    citiBikeData = []\n",
    "\n",
    "    while (citiBikeDataRaw):\n",
    "        instance = citiBikeDataRaw.pop()\n",
    "        date = instance[1].split(\" \")[0].split(\"-\")  # uses the start date of the loan\n",
    "        for record in weatherDataRaw:\n",
    "            if (str(date[0]) == str(record[4]) and str(date[1]) == str(record[2]) and str(date[2]) == str(record[0])):\n",
    "                instance.extend([record[5], record[6], record[7], record[8], record[9]])\n",
    "                citiBikeData.append(instance)\n",
    "\n",
    "    del citiBikeDataRaw\n",
    "    del weatherDataRaw\n",
    "\n",
    "    # Final Columns:\n",
    "    #  0 tripduration\n",
    "    #  1 starttime\n",
    "    #  2 stoptime\n",
    "    #  3 start station id\n",
    "    #  4 start station name\n",
    "    #  5 start station latitude\n",
    "    #  6 start station longitude\n",
    "    #  7 end station id\n",
    "    #  8 end station name\n",
    "    #  9 end station latitude\n",
    "    # 10 end station longitude\n",
    "    # 11 bikeid\n",
    "    # 12 usertype\n",
    "    # 13 birth year\n",
    "    # 14 gender\n",
    "    # 15 start/end station distance\n",
    "    # 16 DayOfWeek\n",
    "    # 17 TimeOfDay\n",
    "    # 18 HolidayFlag\n",
    "    # 19 PRCP\n",
    "    # 20 SNOW\n",
    "    # 21 TAVE\n",
    "    # 22 TMAX\n",
    "    # 23 TMIN\n",
    "\n",
    "    maxLineCount = 250000\n",
    "    lineCounter = 1\n",
    "    fileCounter = 1\n",
    "    outputDirectoryFilename = \"Compiled Data/dataset\"\n",
    "    f = open(outputDirectoryFilename + str(fileCounter) + \".csv\", \"w\")\n",
    "    for line in citiBikeData:\n",
    "        if lineCounter == 250000:\n",
    "            print(f)\n",
    "            f.close()\n",
    "            lineCounter = 1\n",
    "            fileCounter = fileCounter + 1\n",
    "            f = open(outputDirectoryFilename + str(fileCounter) + \".csv\", \"w\")\n",
    "        f.write(\",\".join(map(str, line)) + \"\\n\")\n",
    "        lineCounter = lineCounter + 1\n",
    "\n",
    "    del citiBikeData\n",
    "        \n",
    "endtime = datetime.now()\n",
    "print(\"RunTime: \")\n",
    "print(endtime-starttime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Loading the Compiled Data from CSV\n",
    "\n",
    "Now that we have compiled data files from both CitiBike and the weather data, we want to load that data into a Pandas dataframe for analysis. We iterate and load each file produced above, then assign each column with their appropriate data types. Additionally, we compute the Age Column after producing a default value for missing \"Birth Year\" values. This is discussed further in the Data Quality section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create CSV Reader Function and assign column headers\n",
    "def reader(f, columns):\n",
    "    d = pd.read_csv(f)\n",
    "    d.columns = columns\n",
    "    return d\n",
    "\n",
    "# Identify All CSV FileNames needing to be loaded\n",
    "path = r'Compiled Data'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "    # Define File Columns\n",
    "columns = [\"tripduration\", \"starttime\", \"stoptime\", \"start_station_id\", \"start_station_name\", \"start_station_latitude\",\n",
    "           \"start_station_longitude\", \"end_station_id\", \"end_station_name\", \"end_station_latitude\",\n",
    "           \"end_station_longitude\", \"bikeid\", \"usertype\", \"birth year\", \"gender\", \"LinearDistance\", \"DayOfWeek\",\n",
    "           \"TimeOfDay\", \"HolidayFlag\", \"PRCP\", \"SNOW\", \"TAVE\", \"TMAX\", \"TMIN\"]\n",
    "\n",
    "    # Load Data\n",
    "CitiBikeDataCompiled = pd.concat([reader(f, columns) for f in all_files])\n",
    "\n",
    "    # Replace '\\N' Birth Years with Zero Values\n",
    "CitiBikeDataCompiled[\"birth year\"] = CitiBikeDataCompiled[\"birth year\"].replace(r'\\N','0')\n",
    "\n",
    "    # Convert Columns to Numerical Values\n",
    "CitiBikeDataCompiled[['tripduration', 'birth year', 'LinearDistance','PRCP', 'SNOW', 'TAVE', 'TMAX', 'TMIN']]\\\n",
    "    = CitiBikeDataCompiled[['tripduration', 'birth year','LinearDistance', 'PRCP', 'SNOW', 'TAVE', 'TMAX',\n",
    "                            'TMIN']].apply(pd.to_numeric)\n",
    "\n",
    "    # Convert Columns to Date Values\n",
    "CitiBikeDataCompiled[['starttime', 'stoptime']] \\\n",
    "    = CitiBikeDataCompiled[['starttime', 'stoptime']].apply(pd.to_datetime)\n",
    "\n",
    "    # Compute Age: 0 Birth Year = 0 Age ELSE Compute Start Time Year Minus Birth Year\n",
    "CitiBikeDataCompiled[\"Age\"] = np.where(CitiBikeDataCompiled[\"birth year\"]==0, 0,\n",
    "                                       CitiBikeDataCompiled[\"starttime\"].dt.year - CitiBikeDataCompiled[\"birth year\"])\n",
    "\n",
    "    # Convert Columns to Str Values\n",
    "CitiBikeDataCompiled[['start_station_id', 'end_station_id', 'bikeid', 'HolidayFlag', 'gender']] \\\n",
    "    = CitiBikeDataCompiled[['start_station_id', 'end_station_id', 'bikeid', 'HolidayFlag','gender']].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(CitiBikeDataCompiled))\n",
    "display(CitiBikeDataCompiled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality\n",
    "\n",
    "##### Measurable Data Quality Factors\n",
    "When analyzing our final dataset for accurate measures, there are a few key factors we can easily verify/research:\n",
    "- Computational Accuracy: Ensure data attributes added by computation are correct\n",
    "    + TimeOfDay\n",
    "    + DayOfWeek        \n",
    "    + HolidayFlag\n",
    "    \n",
    "- Missing Data from Source\n",
    "- Duplicate Data from Source\n",
    "- Outlier Detection\n",
    "- Sampling to 500,000 Records for further analysis\n",
    "\n",
    "##### Immesurable Data Quality Factors\n",
    "Although we are able to research these many factors, one computation still may still be lacking information in this dataset. Our LinearDistance attribute computes the distance from  one lat/long coordinate to another. This attribute does not however tell us the 'true' distance a biker traveled before returning the bike. Some bikers may be biking for exercise around the city with various turns and loops, whereas others travel the quickest path to their destination. Because our dataset limits us to start and end locations, we do not have enough information to accurately compute distance traveled. Because of this, we have named the attribute \"LinearDistance\" rather than \"DistanceTraveled\".\n",
    "\n",
    "Below we will walk through the process of researching the 'Measureable' data quality factors mentioned above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Computational Accuracy:TimeOfDay\n",
    "To help mitigate challenges with time series data, we have chosen to break TimeOfDay into 5 categories.\n",
    "These Categories are broken down below:\n",
    "- Morning       5  AM  -  10 AM\n",
    "- Midday        10 AM  -  2  PM\n",
    "- Afternoon     2  PM  -  5  PM\n",
    "- Evening       5  PM  -  10 PM\n",
    "- Night         10 PM  -  5  AM\n",
    "\n",
    "To ensure that these breakdowns are accurately computed, we pulled the distinct list of TimeOfDay assignments by starttime hour. Looking at the results below, we can verify that this categorization is correctly being assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Compute StartHour from StartTime\n",
    "CitiBikeDataCompiled[\"StartHour\"] = CitiBikeDataCompiled[\"starttime\"].dt.hour\n",
    "\n",
    "    # Compute Distinct Combinations of StartHour and TimeOfDay\n",
    "DistinctTimeOfDayByHour = CitiBikeDataCompiled[[\"StartHour\", \"TimeOfDay\"]].drop_duplicates().sort_values(\"StartHour\")\n",
    "\n",
    "    # Print\n",
    "display(DistinctTimeOfDayByHour)\n",
    "\n",
    "    #Clean up Variables\n",
    "del CitiBikeDataCompiled[\"StartHour\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Computational Accuracy:DayOfWeek\n",
    "In order to verify our computed DayOfWeek column, we have chosen one full week from 12/22/2013 - 12/28/2013 to validate. Below is a calendar image of this week to baseline our expected results:\n",
    "\n",
    "<img src=\"https://github.com/msmith-ds/DataMining/blob/master/Project1/Images/Dec_2013_Calendar.png?raw=true\" width=\"300\">\n",
    "\n",
    "To verify these 7 days, we pulled the distinct list of DayOfWeek assignments by StartDate (No Time). If we can verify one full week, we may justify that the computation is correct across the entire dataset. Looking at the results below, we can verify that this categorization is correctly being assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Create DataFrame for StartTime, DayOfWeek within Date Threshold\n",
    "CitiBikeDayOfWeekTest = CitiBikeDataCompiled[(CitiBikeDataCompiled['starttime'].dt.year == 2013)\n",
    "                                             & (CitiBikeDataCompiled['starttime'].dt.month == 12)\n",
    "                                             & (CitiBikeDataCompiled['starttime'].dt.day >= 22)\n",
    "                                             & (CitiBikeDataCompiled['starttime'].dt.day <= 28)][\n",
    "    [\"starttime\", \"DayOfWeek\"]]\n",
    "\n",
    "    # Create FloorDate Variable as StartTime without the timestamp\n",
    "CitiBikeDayOfWeekTest[\"StartFloorDate\"] = CitiBikeDayOfWeekTest[\"starttime\"].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "    # Compute Distinct combinations\n",
    "DistinctDayOfWeek = CitiBikeDayOfWeekTest[[\"StartFloorDate\", \"DayOfWeek\"]].drop_duplicates().sort_values(\n",
    "    \"StartFloorDate\")\n",
    "\n",
    "    #Print\n",
    "display(DistinctDayOfWeek)\n",
    "\n",
    "    # Clean up Variables\n",
    "del CitiBikeDayOfWeekTest\n",
    "del DistinctDayOfWeek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Computational Accuracy:HolidayFlag\n",
    "Using the same week as was used to verify DayOfWeek, w can test whether HolidayFlag is set correctly for the Christmas Holiday. We pulled the distinct list of HolidayFlag assignments by StartDate (No Time). If we can verify one holiday, we may justify that the computation is correct across the entire dataset. Looking at the results below, we expect to see HolidayFlag = 1 only for 12/25/2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Create DataFrame for StartTime, HolidayFlag within Date Threshold\n",
    "CitiBikeHolidayFlagTest = CitiBikeDataCompiled[(CitiBikeDataCompiled['starttime'].dt.year == 2013)\n",
    "                                             & (CitiBikeDataCompiled['starttime'].dt.month == 12)\n",
    "                                             & (CitiBikeDataCompiled['starttime'].dt.day >= 22)\n",
    "                                             & (CitiBikeDataCompiled['starttime'].dt.day <= 28)][\n",
    "    [\"starttime\", \"HolidayFlag\"]]\n",
    "\n",
    "    # Create FloorDate Variable as StartTime without the timestamp\n",
    "CitiBikeHolidayFlagTest[\"StartFloorDate\"] = CitiBikeHolidayFlagTest[\"starttime\"].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "    # Compute Distinct combinations\n",
    "DistinctHolidayFlag = CitiBikeHolidayFlagTest[[\"StartFloorDate\", \"HolidayFlag\"]].drop_duplicates().sort_values(\n",
    "    \"StartFloorDate\")\n",
    "    \n",
    "    #Print\n",
    "display(DistinctHolidayFlag)\n",
    "    \n",
    "    # Clean up Variables\n",
    "del CitiBikeHolidayFlagTest\n",
    "del DistinctHolidayFlag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Missing Data from Source\n",
    "Accounting for missing data is a crucial part of our analysis. At first glance, it is very apparent that we have a large amount of missing data in the Gender and Birth Year attributes from our source CitiBike Data. We have already had to handle for missing Birth Year attributes while computing \"Age\" in our Data Load from CSV section of this paper. This was done to create a DEFAULT value of (0), such that future computations do not result in NA values as well. Gender has also already accounted for missing values with a default value of (0) by the source data. Although we have handled these missing values with a default, we want to ensure that we 'need' these records for further analysis - or if we may remove them from the dataset. Below you will see a table showing the frequency of missing values(or forced default values) by usertype. We noticed that of the 4881384 Subscribing Members in our dataset, only 295 of them were missing Gender information, whereas out of the  680909 Customer Users (Non-Subscribing), there was only one observation where we had complete information for both Gender and Birth Year. This quickly told us that removing records with missing values is NOT an option, since we would lose data for our entire Customer Usertype. These attributes, as well as Age (Computed from birth year) will serve as difficult for use in a classification model attempting to predict usertype. \n",
    "\n",
    "We have also looked at all other attributes, and verified that there are no additional missing values in our dataset. A missing value matrix was produced to identify if there were any gaps in our data across all attributes. Due to the conclusive results in our data, no missing values present, we removed this lackluster visualization from the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NADatatestData = CitiBikeDataCompiled[[\"usertype\",\"gender\", \"birth year\"]]\n",
    "\n",
    "NADatatestData[\"GenderISNA\"] = np.where(CitiBikeDataCompiled[\"gender\"] == '0', 1, 0)\n",
    "NADatatestData[\"BirthYearISNA\"] = np.where(CitiBikeDataCompiled[\"birth year\"] == 0, 1,0)\n",
    "\n",
    "NAAggs = pd.DataFrame({'count' : NADatatestData.groupby([\"usertype\",\"GenderISNA\", \"BirthYearISNA\"]).size()}).reset_index()\n",
    "\n",
    "display(NAAggs)\n",
    "\n",
    "del NAAggs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Duplicate Data from Source\n",
    "To ensure that there are no duplicate records in our datasets, we ensured that the number of records before and after removing potential duplicates were equal to eachother. This test passed, thus we did not need any alterations to the dataset based on duplicate records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(CitiBikeDataCompiled) == len(CitiBikeDataCompiled.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Outlier Detection\n",
    "\n",
    "**Trip Duration**\n",
    "In analyzing a Box Plot on trip duration values, we find extreme outliers present. With durations reaching up to 72 days in the most extreme instance, our team decided to rule out any observation with a duration greater than a 24 period. The likelihood of an individual sleeping overnight after their trip with the bike still checked out is much higher after the 24 hour period. This fact easily skews the results of this value, potentially hurting any analysis done. We move forward with removing a total of 457 observations based on trip duration greater than 24 hours (86,400 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "#CitiBikeDataCompiledBackup = CitiBikeDataCompiled\n",
    "#CitiBikeDataCompiled = CitiBikeDataCompiledBackup\n",
    "\n",
    "    # BoxPlot tripDuration - Heavy Outliers!\n",
    "sns.boxplot(y = \"tripduration\", data = CitiBikeDataCompiled)\n",
    "sns.despine()\n",
    "    \n",
    "    # How Many Greater than 24 hours?\n",
    "print(len(CitiBikeDataCompiled[CitiBikeDataCompiled[\"tripduration\"]>86400]))\n",
    "\n",
    "    # Remove > 24 Hours\n",
    "CitiBikeDataCompiled = CitiBikeDataCompiled[CitiBikeDataCompiled[\"tripduration\"]<86400]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once outliers are removed, we run the boxplot again, still seeing skewness in results. To try to mitigate this left-skew distribution, we decide to take a log transform on this attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "    # BoxPlot Trip Duration AFTER removal of outliers\n",
    "sns.boxplot(y = \"tripduration\", data = CitiBikeDataCompiled)\n",
    "sns.despine()\n",
    "\n",
    "    # Log Transform Column Added\n",
    "CitiBikeDataCompiled[\"tripdurationLog\"] = CitiBikeDataCompiled[\"tripduration\"].apply(np.log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "    # BoxPlot TripDurationLog\n",
    "sns.boxplot(y = \"tripdurationLog\", data = CitiBikeDataCompiled)\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age**\n",
    "Similarly, we look at the distribution of Age in our dataset. Interestingly, it seems we have several outlier observations logging their birth year far enough back to cause their age to compute as 115 years old. Possible reasons for these outlier ages could be data entry errors by those who do not enjoy disclosing personal information, or possibly account sharing between a parent and a child - rendering an inaccurate data point to those actually taking the trip. Our target demographic for this study are those individuals under 65 years of age, given that they are the likely age groups to be in better physical condition for the bike share service. Given this target demographic, and the poor entries causing extreme outliers, we have chosen to limit out dataset to observations up to 65 years of age. This change removed an additional 53824 records from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "    # BoxPlot Age - Outliers!\n",
    "sns.boxplot(y = \"Age\", data = CitiBikeDataCompiled[CitiBikeDataCompiled[\"Age\"]!= 0])\n",
    "sns.despine()\n",
    "    \n",
    "    # How Many Greater than 65 years old?\n",
    "print(len(CitiBikeDataCompiled[CitiBikeDataCompiled[\"Age\"]>65]))\n",
    "\n",
    "    # Remove > 65 years old\n",
    "CitiBikeDataCompiled = CitiBikeDataCompiled[CitiBikeDataCompiled[\"Age\"]<=65]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "    # BoxPlot Age - removed Outliers!\n",
    "sns.boxplot(y = \"Age\", data = CitiBikeDataCompiled[CitiBikeDataCompiled[\"Age\"]!= 0])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Record Sampling to 500,000 Records\n",
    "Given the extremely large volume of data collected, we have have decided to try to sample down to ~ 1/10th of the original dataset for a total of 500,000 records. Before taking this action, however we wanted to ensure that we keep data proportions reasonable for analysis and ensure we do not lose any important demographic in our data.\n",
    "\n",
    "Below we compute the percentage of our Dataset that comprises of Customers vs. Subscribers. We want to make sure that our sample is representative of the population dataset, so we stratify our sample to match the original data proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "UserTypeDist = pd.DataFrame({'count' : CitiBikeDataCompiled.groupby([\"usertype\"]).size()}).reset_index()\n",
    "display(UserTypeDist)\n",
    "\n",
    "UserTypeDist.plot.pie(y = 'count', labels = ['Customer', 'Subscriber'], autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these distribution percentages we are then able to compute the sample size for each usertype and then take a random sample within each group. Below you will see that our sampled distribution matches that of the original Dataset between Customers and Subscriber Usertypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SampleSize = 500000\n",
    "\n",
    "CustomerSampleSize_Seed   = int(round(SampleSize * 12.4 / 100.0,0))\n",
    "SubscriberSampleSize_Seed = int(round(SampleSize * 87.6 / 100.0,0))\n",
    "\n",
    "CitiBikeCustomerDataSampled = CitiBikeDataCompiled[CitiBikeDataCompiled[\"usertype\"] == 'Customer'].sample(n=CustomerSampleSize_Seed, replace = False, random_state = CustomerSampleSize_Seed)\n",
    "CitiBikeSubscriberDataSampled = CitiBikeDataCompiled[CitiBikeDataCompiled[\"usertype\"] == 'Subscriber'].sample(n=SubscriberSampleSize_Seed, replace = False, random_state = SubscriberSampleSize_Seed)\n",
    "\n",
    "CitiBikeDataSampled = pd.concat([CitiBikeCustomerDataSampled,CitiBikeSubscriberDataSampled])\n",
    "\n",
    "print(len(CitiBikeDataSampled))\n",
    "\n",
    "UserTypeDist = pd.DataFrame({'count' : CitiBikeDataSampled.groupby([\"usertype\"]).size()}).reset_index()\n",
    "display(UserTypeDist)\n",
    "\n",
    "UserTypeDist.plot.pie(y = 'count', labels = ['Customer', 'Subscriber'], autopct='%1.1f%%')\n",
    "\n",
    "del CitiBikeDataCompiled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize appropriate statistics\n",
    "\n",
    "With the massive data set randomly sampled out to 500000 entries, we can more easily begin to explore the data available to us. First we began by running basic descriptive statistics for the data to get a high level, top down view of the Citi Bike Rentals we sampled.\n",
    "\n",
    "##### Descriptive Statistics\n",
    "\n",
    "With the first table, we looked at the categorical/non-numerical data that was available to us. For the stations found within the sampled data, we managed to sample the same number of unique stations that is found in the collected data set giving us a good start in assuming a representative sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CitiBikeDataSampled.describe(include=['O']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we reviewed our numerical data, pulling mean, standard deviation, as well as the quartiles for each feature. Trip Duration, as a reminder, is measured in seconds, with the minimum trip duration being 1 minute. Shorter trip durations were elimindated by Citi Bike in the source data to remove possible errors as a result of people putting a bike back after removing it among other possible explanations for such short ride times.\n",
    "\n",
    "Among all the numerical statistics, we're largely focused on Age, Trip Duration, Linear Distance as well as the weather statistical data. Birth Year was primarily used to calculate Age from trip start date. The data presented here for station latitudes and longitudes is largely unable to be used in this form, but will prove valueable for constructing location heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CitiBikeDataSampled.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlated Numerical Variables\n",
    "\n",
    "Before we begin visualization some of the more specific variable interactions it's important to see the magnitude of possible correlations which we found using Panda's Pearson Correlation function. We'll ignore the obvious, such as birth year's correlation with age and tripdurationLog's correlation with tripduration, as well as most correlations involving latitude and longitude.\n",
    "\n",
    "Right away we noticed the large correlations between start station coordinates and end station coordinates. At first, we suspected that it was because renters would start and end at the same station, but we ruled that out by running a count of all records where the start_station_id equaled the end_station_id and found it to contain less than 2.5% of all records. It's far more likely that we're probably seeing colinearity due to the close proximity of all the stations and the low variance between coordinates.\n",
    "\n",
    "Other than that, no singular set of features displayed strong correlation. Possibly for tripduration and LinearDistance, which is only to be expected. That said, Age did seem to have some indication of correlation with trip duration, if weak, as well as correlations with the weather attributes. This possibly indicates that age plays a factor in determining whether or not somone rents a bike during certain weather, and how far or how long they travel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CitiBikeDataSampled.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CitiBikeDataSampled.query('start_station_id == end_station_id')[\"start_station_id\"].count() / CitiBikeDataSampled[\"start_station_id\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Covariance Among Numerical Attributes\n",
    "\n",
    "We also examined covariance among numerical attributes finding relatively high covariance between tripduration and the known weather attributes as well as age, further cementing the idea that these factors play into whether or not a person decides to rent and if they do, how long they ride for. Eventually we'll explore at what point these decisions to ride ultimately culminate in the transition from customer to describer, but for now, let's examine age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CitiBikeDataSampled.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Age Distribution\n",
    "\n",
    "With age, we found a right skewed distribution (common with population age variables) with the majority of our renters falling below 35. As an additional note, nearly all the age data was provided by subscribers as most customers (non-subscribers) either did not input an age, or input an age that fell outside our expectations as described in data quality. All further analysis of age and its relationship with other attributes will be done through the lens of knowing that it only describes subscribers and not necessarily the entire population of Citi Bike Riders/Renters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(CitiBikeDataSampled.query('Age != 0')[\"Age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Linear Distance vs Trip Duration\n",
    "\n",
    "As part of our initial exploration of the data and building out all the attributes we could for examining the data set was attempting to see how far people were traveling during their rental period. Shy of making navigation calls to Google Maps or someother navigation service, we decided to calculate linear distance between the start and end station to give us the approximate distance traveled. We acknowledge, however, that riders weren't necessarily traveling from one station to another directly - quite a few rode for several hours and returned their bikes to stations only blocks apart. Likewise, there existed a number of riders that apparently traveled zero miles despite having trip durations in the minutes.\n",
    "\n",
    "Below is a joint grid plotted out with distribution graphs on each axis for tripdurationLog and tripdistance. While it's not a perfect correlation, we do see that both are skewed in regards to higher values with a positive correlation. Further analysis will be necessary to draw any statistically significant conclusions, but this data combined with a study on average biking speed could be used to determine whether or not riders are simply using the bikes as transportation from one station to another, or as a means to travel outside the range of those stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvd = sns.JointGrid(x=\"tripdurationLog\", y=\"LinearDistance\", data=CitiBikeDataSampled.query(\"LinearDistance > 0\"))\n",
    "dvd = dvd.plot(sns.regplot, sns.distplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the most interesting attributes\n",
    "\n",
    "To re-iterate, our main objectives in analyzing these data are to determine which attributes have greatest bearing on predicting a rider's type (Customer vs. Subscriber) and to gain a better understanding of rider behavior as a function of external factors. Many attributes in this data set will eventually be used in subsequent labs to answer these questions. The primary attributes on which we will focus our attention in this section, however, are as follows:\n",
    "- Starting Location\n",
    "- Day of the Week\n",
    "- Time of Day\n",
    "- Trip Duration (both log and non-log)\n",
    "- Linear Distance\n",
    "- Gender\n",
    "- Age\n",
    "\n",
    "Over the course of this section, we will review these top attributes in some detail and discuss the value of using our chosen visualizations. Note also that merged weather data is of significant interest as well. As we desire to heavily compare weather conditions against various rider habits, however, we will refrain from focusing on weather-related attributes until the subsequent sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Geophysical Start Stations HeatMap\n",
    "Before discussing the following heatmap in detail, it is worth noting some special steps required to use the gmaps module in Python in case the reader is interested in rendering our code to plot data on top of Google's maps (Note full instructions are available at https://media.readthedocs.org/pdf/jupyter-gmaps/latest/jupyter-gmaps.pdf)\n",
    "\n",
    "Besides having Jupyter Notebook installed on one's computer with extensions enabled (default if using Anaconda) and installing the gmaps module using pip, the following line should be run from within the command terminal. This is only to be done once and should be done when Jupyter Notebook is not running.\n",
    "```\n",
    "$ jupyter nbextension enable --py gmaps\n",
    "```\n",
    "In addition to running the above line in the command prompt, a Standard Google API user key will need obtained from https://developers.google.com/maps/documentation/javascript/get-api-key. This only needs done once and is necessary to pull the Google map data into the Jupyter Notebook environment. The key is entered in the *gmaps.configure()* line as shown in the below cell. We have provided our own private key in the meantime for the reader's convenience.\n",
    "\n",
    "Now on to the data visualization... This geological heatmap visualization is interactive; however, the kernel must run the code block each time our Jupyter Notebook file is opened due to the API key requirement. Therefore, we've captured some interesting views to aid in our discussion and have included them as embedded images.\n",
    "\n",
    "The start station heatmap represents the start station location data via attributes *start_station_latitude* and *start_station_longitude*. It identifies areas of highest and lowest concentration for trip starts. The location data is important as it helps us understand where the areas of highest activity are and, as will be seen in one of our later sections, will play an important role in identifying riders as regular customers or subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gmaps.configure(api_key=\"AIzaSyAsBi0MhgoQWfoGMSl5UcD-vR6H76cntxg\") # Load private Google API key\n",
    "\n",
    "locations = CitiBikeDataSampled[['start_station_latitude', 'start_station_longitude']].values.tolist()\n",
    "\n",
    "m = gmaps.Map()\n",
    "heatmap_layer = gmaps.Heatmap(data = locations)\n",
    "m.add_layer(heatmap_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overall view quickly reveals that station data was only provided for areas of NYC south of Manhattan and mostly north of Brooklyn. This could either mean that the bike share program had not yet expanded into these other areas at the time of data collection or that the data simply wasn't included (as mentioned previously, many test sites were being used during this time frame but CitiBike did not include them with this data set).\n",
    "\n",
    "Within the range of trip start frequency from the least number of trips (green) to the most trips (red), green and yellow indicate low to medium trip activity in most areas. However, higher pockets of concentration do exist in some places. We will attempt to put this visualization to good use by focusing in on one of these hotspots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/msmith-ds/DataMining/blob/master/Project1/Images/All_StartLocations.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prominant heatspot occurs just east of Bryant Park and the Midtown map label. Zooming into this area (via regular Google Map controls as the rendered visual is interactive) allows for a closer look. A snapshot of this zoomed in image is embedded below. The hotspot seems slightly elongated and stands out from among the other stations. Zooming in further will help to understand why this is and may shed some light on the higher activity in this area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/msmith-ds/DataMining/blob/master/Project1/Images/All_StartLocationsZoom1.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zooming in to this area further helps us see that two stations are very close together. Even so, why might there be such high rider activity at these stations? This higher activity is likely affected by the stations' proximity to the famous Grand Central Station. As commuters and recreationalists alike arrive by train at Grand Central, it is natural that many of them may choose to continue their journey via the two closest bike share stations nearby. When the northernmost bike share station runs out of bikes, riders likely go to the next station to begin their ride instead.\n",
    "\n",
    "By understanding the dynamics of geographical activity within this data set and the amenities that surround each station, we will be able to more efficiently leverage the data to make our classification and regression predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/msmith-ds/DataMining/blob/master/Project1/Images/All_StartLocationsZoom2.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box Plot for Log Trip Duration by Day of the Week\n",
    "Another attribute of interest is that of trip duration and days of the week. It can be expected that activity should vary depending on what day of the week riders are traveling. Not only are trip durations expected to vary, but with further analysis we expect the days of travel to have some influence on whether riders are bike share subscribers or not. To obtain a quick understanding of day-to-day variance in trip duration, a box plot is used.\n",
    "\n",
    "The following interactive box plots are setup such that the log of trip duration is on the y-axis with the categorical days of the week along the x-axis. Once again, the log transformed trip duration is used to help normalize the distribution for easier analysis. The plots reveal that trip durations do not vary much throughout the week. However, there is some increase on the weekends. Zooming in on the plot to focus in mainly on the IQR regions helps to put this increase in activity into perspective.\n",
    "\n",
    "Though further analysis would be required, the data suggests that riders are spending more time riding on Saturdays and Sundays. Of greater interest will be Customer vs. Subscriber activity across each day of the week. This will be discussed further later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td = CitiBikeDataSampled.tripdurationLog\n",
    "\n",
    "sun = td.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Sunday']\n",
    "mon = td.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Monday']\n",
    "tue = td.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Tuesday']\n",
    "wed = td.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Wednesday']\n",
    "thu = td.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Thursday']\n",
    "fri = td.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Friday']\n",
    "sat = td.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Saturday']\n",
    "\n",
    "sunday = go.Box(y=sun, name='Sunday')\n",
    "monday = go.Box(y=mon, name='Monday')\n",
    "tuesday = go.Box(y=tue, name='Tuesday')\n",
    "wednesday = go.Box(y=wed, name='Wednesday')\n",
    "thursday = go.Box(y=thu, name='Thursday')\n",
    "friday = go.Box(y=fri, name='Friday')\n",
    "saturday = go.Box(y=sat, name='Saturday')\n",
    "\n",
    "layout = go.Layout(title='Log Trip Duration by Day of Week', xaxis=dict(title='DayOfWeek'), yaxis=dict(title='tripdurationLog (log sec)'))\n",
    "\n",
    "data = [sunday, monday, tuesday, wednesday, thursday, friday, saturday]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box Plot for Linear Trip Distance by Day of the Week\n",
    "In follow-up to the previous log trip duration box plots, it is also worth reviewing linear distance traveled by riders for each day of the week. Linear distance traveled also appears to remain constant throughout the week for all riders. Unlike the trip duration, there seems to be little change in distance even on the weekends. While change in distance does remain constant throughout the week, grouping changes in distance by other categories later may help to reveal more about rider activity in the data. This will be the case with user typer as seen shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ld = CitiBikeDataSampled.LinearDistance\n",
    "\n",
    "sun = ld.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Sunday']\n",
    "mon = ld.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Monday']\n",
    "tue = ld.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Tuesday']\n",
    "wed = ld.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Wednesday']\n",
    "thu = ld.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Thursday']\n",
    "fri = ld.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Friday']\n",
    "sat = ld.loc[CitiBikeDataSampled[\"DayOfWeek\"] == 'Saturday']\n",
    "\n",
    "sunday = go.Box(y=sun, name='Sunday')\n",
    "monday = go.Box(y=mon, name='Monday')\n",
    "tuesday = go.Box(y=tue, name='Tuesday')\n",
    "wednesday = go.Box(y=wed, name='Wednesday')\n",
    "thursday = go.Box(y=thu, name='Thursday')\n",
    "friday = go.Box(y=fri, name='Friday')\n",
    "saturday = go.Box(y=sat, name='Saturday')\n",
    "\n",
    "layout = go.Layout(title='Linear Distance by Day of Week', xaxis=dict(title='DayOfWeek'), yaxis=dict(title='LinearDistance (miles)'))\n",
    "\n",
    "data = [sunday, monday, tuesday, wednesday, thursday, friday, saturday]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Violin Plot for Log Trip Duration by Day of the Week and Gender\n",
    "As discussed previously, we do not have complete coverage in our dataset of gender values. Nevertheless, we are interested to know if there are significant differences between male and female bikers. Since the majority of customers (i.e. non-subscribers) do not provide CitiBike with gender details, this research is indicative mainly for subscribing members. We chose to first build a violin plot with the day of week on the x-axis and log trip duration on the y axis. We broke down the data into two separate violins per day for male vs. female results. As discussed earlier, we see consistencies in trip duration from day to day in both male and female bikers. Interestingly females, in general, have ridden for longer durations than males. One could speculate that this could be due to additional excursions (e.g. shopping, events, etc.), or slower biking speeds during the trip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", palette=\"pastel\", color_codes=True)\n",
    "\n",
    "# Load our subset data set\n",
    "sub = CitiBikeDataSampled.query('gender != \"0\"')\n",
    "\n",
    "# Draw a nested violinplot and split the violins for easier comparison\n",
    "sns.violinplot(x=\"DayOfWeek\", y=\"tripdurationLog\", hue=\"gender\", data=sub, split=False,\n",
    "               inner=\"quart\", palette={\"1\": \"b\", \"2\": \"pink\"}, linewidth=0.5,\n",
    "              order=[\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"])\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Violin Plot for Linear Distance by Day of the Week and Gender\n",
    "To complement these findings above (Log Trip Duration by Day of Week and Gender) and attempt to gain some additional insight into some of the reasoning behind females with longer trip durations, we build a second violoin plot. This time, we chose to plot day of week on the x-axis and LinearDistance on the y-axis. This yielded much less insightful information, as \"linear distance\" is not indicative of the actual \"trip distance\". The plotted linear distances appear to be fairly consistent both from day to day (as discussed previously), and between males and females. Further research and / or more insightful data points, such as \"trip distance\", or \"average trip speed\" could help gain further insights. These additional data points will be discussed later in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"DayOfWeek\", y=\"LinearDistance\", hue=\"gender\", data=sub, split=False,\n",
    "               inner=\"quart\", palette={\"1\": \"b\", \"2\": \"pink\"}, linewidth=0.5,\n",
    "              order=[\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"])\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stacked Bar Plot Trip Duration by Day of Week and Time of Day\n",
    "Another attribute that may potentially reveal much about Customer vs. Subscriber activity is time of day. Again, the time of day attribute is a categorical variable with a group assigned to a ride depending on which range of hours throughout the day the bike ride begins. While trip durations are expected to change by time of day, it would likely be misleading to lump times of day regardless of days of the week since rider activity is expected to change based on work schedule or weekend activities.\n",
    "\n",
    "The interactive stacked bar plot below is more suited for raw trip duration data rather than log-transformed data. The raw data accentuates the true differences from day-to-day and across time slots. Because the raw data is strongly left-skewed, the median value from each day-time grouping was obtained and rendered in the plot. By stacking the median trip durations for each time slot for each respective day, we are able to better understand the time slot proportionality differences across each day of the week. Stacking the time slot median trip durations also provides a total sum of the time slot medians for each day, making it easier compare overall activity for each day.\n",
    "\n",
    "Correlating with the \"Box Plot for Log Trip Duration by Day of the Week\" visualization above, trip duration activity does increase on the weekends. Not only that, but hovering over each day bar reveals that Midday, Afternoon, and Evening activity are noticeably higher on Saturdays and Sundays than they are on weekdays whereas Morning and Night activity is relatively consistent. Understanding these trends may help us understand rider intent throughout the week and how it affects their decision to subscribe to Citi Bike or not. Being cognisant of these trends may also improve inventory at some stations at peaks times of the day when also considering start and end location frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td = CitiBikeDataSampled.tripduration\n",
    "\n",
    "# Extract morning data\n",
    "sunMorning = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Sunday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Morning')]\n",
    "monMorning = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Monday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Morning')]\n",
    "tueMorning = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Tuesday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Morning')]\n",
    "wedMorning = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Wednesday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Morning')]\n",
    "thuMorning = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Thursday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Morning')]\n",
    "friMorning = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Friday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Morning')]\n",
    "satMorning = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Saturday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Morning')]\n",
    "\n",
    "# Extract midday data\n",
    "sunMidday = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Sunday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Midday')]\n",
    "monMidday = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Monday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Midday')]\n",
    "tueMidday = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Tuesday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Midday')]\n",
    "wedMidday = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Wednesday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Midday')]\n",
    "thuMidday = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Thursday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Midday')]\n",
    "friMidday = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Friday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Midday')]\n",
    "satMidday = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Saturday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Midday')]\n",
    "\n",
    "# Extract afternoon data\n",
    "sunAfternoon = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Sunday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Afternoon')]\n",
    "monAfternoon = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Monday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Afternoon')]\n",
    "tueAfternoon = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Tuesday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Afternoon')]\n",
    "wedAfternoon = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Wednesday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Afternoon')]\n",
    "thuAfternoon = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Thursday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Afternoon')]\n",
    "friAfternoon = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Friday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Afternoon')]\n",
    "satAfternoon = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Saturday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Afternoon')]\n",
    "\n",
    "# Extract evening data\n",
    "sunEvening = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Sunday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Evening')]\n",
    "monEvening = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Monday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Evening')]\n",
    "tueEvening = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Tuesday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Evening')]\n",
    "wedEvening = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Wednesday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Evening')]\n",
    "thuEvening = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Thursday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Evening')]\n",
    "friEvening = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Friday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Evening')]\n",
    "satEvening = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Saturday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Evening')]\n",
    "\n",
    "# Extract night data\n",
    "sunNight = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Sunday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Night')]\n",
    "monNight = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Monday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Night')]\n",
    "tueNight = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Tuesday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Night')]\n",
    "wedNight = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Wednesday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Night')]\n",
    "thuNight = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Thursday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Night')]\n",
    "friNight = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Friday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Night')]\n",
    "satNight = td.loc[(CitiBikeDataSampled[\"DayOfWeek\"] == 'Saturday') & (CitiBikeDataSampled[\"TimeOfDay\"] == 'Night')]\n",
    "\n",
    "# Compute morning averages by day\n",
    "def compAvgs(sun, mon, tue, wed, thu, fri, sat):\n",
    "    avgs = []\n",
    "    avgs.append(statistics.median(sun))\n",
    "    avgs.append(statistics.median(mon))\n",
    "    avgs.append(statistics.median(tue))\n",
    "    avgs.append(statistics.median(wed))\n",
    "    avgs.append(statistics.median(thu))\n",
    "    avgs.append(statistics.median(fri))\n",
    "    avgs.append(statistics.median(sat))\n",
    "    return avgs\n",
    "\n",
    "morningAvg = compAvgs(sunMorning, monMorning, tueMorning, wedMorning, thuMorning, friMorning, satMorning)\n",
    "middayAvg = compAvgs(sunMidday, monMidday, tueMidday, wedMidday, thuMidday, friMidday, satMidday)\n",
    "afternoonAvg = compAvgs(sunAfternoon, monAfternoon, tueAfternoon, wedAfternoon, thuAfternoon, friAfternoon, satAfternoon)\n",
    "eveningAvg = compAvgs(sunEvening, monEvening, tueEvening, wedEvening, thuEvening, friEvening, satEvening)\n",
    "nightAvg = compAvgs(sunNight, monNight, tueNight, wedNight, thuNight, friNight, satNight)\n",
    "\n",
    "# Define bar plot features\n",
    "x=['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "morning = go.Bar(x=x, y=morningAvg, name='Morning')\n",
    "midday = go.Bar(x=x, y=middayAvg, name='Midday')\n",
    "afternoon = go.Bar(x=x, y=afternoonAvg, name='Afternoon')\n",
    "evening = go.Bar(x=x, y=eveningAvg, name='Evening')\n",
    "night = go.Bar(x=x, y=nightAvg, name='Night')\n",
    "\n",
    "# Combine features and render bar plot\n",
    "data = [morning, midday, afternoon, evening, night]\n",
    "layout = go.Layout(barmode='stack', title='Trip Duration by Day of Week and Time of Day',\n",
    "                   xaxis=dict(title='DayOfWeek'), yaxis=dict(title='tripdurationLog (sec)'))\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contour Plot for Log Trip Duration with Respect to Age\n",
    "\n",
    "Our team was interested in the correlation between the Log of Trip Duration and Age. To accomplish this, we decided to produce a joint density correlation plot between the log trip duration and Age. Once again, due to missing \"birth year\" data in our customer (non-subscribing) users - these insights are slightly skewed in terms of interpreting a pearson's r value produced by the correlation plot. Further computations, only on the dataset for those observations that do not contain an age of zero, provide a pearson's R value of .048. This is a very low positive correlation, confirming what is seen visually in the joint plot, with very little change in trip duration as rider age increases. What was interesting to see was the difference between the Age = 0 density rings, vs. the rest of the dataset. As was discussed previously, Age = 0 records mainly consist of customer (non-subscribing) users - thus we can see that the majority of trip durations for customers is greater than that of subscribing users. This is discussed in more detail later in the paper, but one could infer that this is possibly due to subscriber usage via routine trips vs. customer usage via events, trails, etc. Finally, we can easily see via the core density ring areas that the majority of trips by subscribing members are taken by individuals between ~25-35 years old and ~518 seconds (e^6.25). This matched our suspected core member age demographic, as these are likely working individuals in good physical condition for consistent riding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont = sns.jointplot(x=CitiBikeDataSampled.Age, y=CitiBikeDataSampled.tripdurationLog, kind='kde', color='r', )\n",
    "\n",
    "pearsondata = CitiBikeDataSampled[CitiBikeDataSampled[\"Age\"]!= 0][[\"Age\", \"tripdurationLog\"]]\n",
    "print(pearsonr(pearsondata.Age,pearsondata.tripdurationLog))\n",
    "\n",
    "del pearsondata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Relationships Between Attributes\n",
    "##### HeatMap of TripDuration by Day of Week and Time of Day\n",
    "\n",
    "Although we have previously analyzed plots for both day of week and time of day trip durations, we were interested in further exploring in a different light the median trip duration values within specific days and / or time of days groupings. To do this, we produced a HeatMap of Median Trip Duration raw values (Median within Time of Day and Day of Week Groupings) with Time of Day (Ordered Morning - Night) and Day of Week (Ordered Sun. - Sat.) on the Y Axis. Right off the bat, we see the grouping pair with the largest median trip duration is Saturday Afternoons (2-5PM). Also, we can see that weekend trips are generally longer than weekday trips, with emphasis on Midday - Evening starttimes. Interestingly, we see that consistently, trip durations are higher in the evenings - probably due to travelers using the services after work hours. Most of these results, were what the team expected, and had hoped to see. In general, using median times within groups of [Day of Week, Time of Day] pairs, we observed that evenings and weekends received the largest trip durations, whereas weekday mornings received the lowest trip durations. This information could be useful for Citi Bike, in that they would know which times of day / days of week they needed to focus on driving promotions, events, etc. to increase traffic flow. Also, knowing that trips are generally longer during the weekend, could explain reasons for bike availability concerns. Bike availability is a huge part of this bike share service, and creates a huge impact on travelers satisfaction when bikes aren't available at their closest station.  Combining this information with geocoordinate density maps discussed in this paper could help them support bike station shift services - moving bikes from less travelled areas to heavier travelled areas. This could potentialy help mitigate some availability loss in their service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "grouped = CitiBikeDataSampled.groupby(['DayOfWeek', 'TimeOfDay'], as_index=False)\n",
    "groupAgg = grouped.aggregate(np.median)\n",
    "groupAgg['DayOfWeek'] = pd.Categorical(groupAgg['DayOfWeek'], ['Sunday',\n",
    "                                                               'Monday',\n",
    "                                                               'Tuesday',\n",
    "                                                               'Wednesday',\n",
    "                                                               'Thursday',\n",
    "                                                               'Friday',\n",
    "                                                               'Saturday'])\n",
    "\n",
    "groupAgg['TimeOfDay'] = pd.Categorical(groupAgg['TimeOfDay'], ['Morning',\n",
    "                                                               'Midday',\n",
    "                                                               'Afternoon',\n",
    "                                                               'Evening',\n",
    "                                                               'Night'])\n",
    "\n",
    "groupAgg = groupAgg.sort_values(by=['DayOfWeek','TimeOfDay'])\n",
    "\n",
    "dist0 = groupAgg[[\"DayOfWeek\", \"TimeOfDay\", \"tripduration\"]]\n",
    "dist1 = dist0.pivot(\"DayOfWeek\", \"TimeOfDay\", \"tripduration\")\n",
    "\n",
    "# Render DayOfWeek vs. TimeOfDay heatmap for \n",
    "sns.heatmap(dist1, annot=True, fmt=\"f\", linewidths=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log Trip Duration with respect to Average Temperature Joint Density Plot\n",
    "\n",
    "We were interested in seeing the effect temperature has on trip duration. To achieve this we created a joint density correlation plot between Average Temperature (TAVE) and the Log of Trip Duration (tripdurationLog). Interestingly, we did not see as high of a correlation as expected. With a Pearsons R correlation values of .15, there is a very small positive correlation of increasing trip duration (as depicted by a log transformation) as average temperatre increases. The team expected much more correlation, as we thought that individuals would not enjoy being on a bike during cold weather. We do however, see that the density of trip durations is highest around 75 degrees fahrenheit. This matched our expectations because although durations remained fairly unchanged, the number of trips taken decreased as average temperature decreased. This is also depicted by the skewed distribution shown on the Y axis(right side of plot). Possibly, the reason we did not see as large of a change in trip duration is due to the nature of subscriber usage of the bike share service. It is possible that subscribers use the bike share service for routine travel around the city: grocery trips, work trips, trips to meet friends, etc.. All of these things, if the bike share service is a core means for transportation, have not changed distances due to cold weather, therefore you see the number of riders decrease while keeping durations mostly consistent. Further research on this correlation between subscribers vs.  customers and potentially some surveys to subscribing members could assist with proving this theory. If these insights are true during cold weather months, it could help marketing promotions for the service to working individuals in attempts to increase bike share traffic for routine trips. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cont = sns.jointplot(x=CitiBikeDataSampled.tripdurationLog, y=CitiBikeDataSampled.TAVE, kind='kde')\n",
    "#cont.plot_joint(plt.scatter, c=\"w\", s=3, linewidth=0.5, marker=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Relationships Between Features and Prediction Class\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Customer vs. Subscriber Trip Duration by Day of the Week Split Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", palette=\"pastel\", color_codes=True)\n",
    "\n",
    "# Load our subset data set\n",
    "sub = CitiBikeDataSampled\n",
    "\n",
    "# Draw a nested violinplot and split the violins for easier comparison\n",
    "sns.violinplot(x=\"DayOfWeek\", y=\"tripdurationLog\", hue=\"usertype\", data=sub, split=True,\n",
    "               inner=\"quart\", palette={\"Subscriber\": \"g\", \"Customer\": \"y\"})\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Customer vs. Subscriber Linear Trip Distance by Day of the Week Split Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", palette=\"pastel\", color_codes=True)\n",
    "\n",
    "# Load our subset data set\n",
    "sub = CitiBikeDataSampled\n",
    "\n",
    "# Draw a nested violinplot and split the violins for easier comparison\n",
    "sns.violinplot(x=\"DayOfWeek\", y=\"LinearDistance\", hue=\"usertype\", data=sub, split=True,\n",
    "               inner=\"quart\", palette={\"Subscriber\": \"g\", \"Customer\": \"y\"})\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Geographic Heatmap Comparing Customer vs. Subscriber Start Station Activity\n",
    "\n",
    "After visualizing the overall dataset locations with a heatmap over NYC, we decided to take the visualization one step further. This time, we broke the dataset into two segments: Customer vs. Subscriber. Below is two separate gmap heatmaps containing geographic densities for each usertype. What we found assisted our theories on customer vs. subscriber usage tendencies. Seen first, the Customer heatmap overall contains much fewer dense regions. This helps to confirm our suspicions infering Customer bikers as less \"routine\" than subscribing bikers. When looking around for the most dense region in this heatmap, one point stuck out as particularly interesting: The Zoo. When comparing this region on the Subscriber gmap, we did not see the same type of traffic! This helps assist our theories that customer bikers use the service more for events, shopping,  or one-time use convenience. On the subscriber gmap, the most dense region, is that near the Grand Central Station as discussed earlier - assisting in the opposing theory for subscribing members as routine trips to work, groceries, etc. as they consistently use the bike share service as a means to reach the metro station."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Customer Users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "customerData = CitiBikeDataSampled.query('usertype == \"Customer\"')\n",
    "customerLoc = customerData[['start_station_latitude', 'start_station_longitude']].values.tolist()\n",
    "\n",
    "cmap = gmaps.Map()\n",
    "customer_layer = gmaps.Heatmap(data=customerLoc)#, fill_color=\"red\", stroke_color=\"red\", scale=3)\n",
    "cmap.add_layer(customer_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/msmith-ds/DataMining/blob/master/Project1/Images/CMAP_StartLocations_Satellite.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subscriber Users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subscriberData = CitiBikeDataSampled.query('usertype == \"Subscriber\"')\n",
    "subscriberLoc = subscriberData[['start_station_latitude', 'start_station_longitude']].values.tolist()\n",
    "\n",
    "smap = gmaps.Map()\n",
    "subscriber_layer = gmaps.Heatmap(data=subscriberLoc)#, fill_color=\"green\", stroke_color=\"green\", scale=2)\n",
    "smap.add_layer(subscriber_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/msmith-ds/DataMining/blob/master/Project1/Images/SMAP_StartLocations_Satellite.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age, Trip Duration, and Linear Distance vs Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(CitiBikeDataSampled, x_vars=[\"PRCP\",\"SNOW\",\"TAVE\",\"TMAX\",\"TMIN\"], y_vars=[\"tripduration\",\"Age\",\"LinearDistance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features That Could Be Added\n",
    "Beyond the features we already chose to add to the original data set, there are others of particular interest that would bring much value to the existing data as well. We've documented some of our ideas below:\n",
    "- ***Event/Restaurant/Retail Data:*** Given that we have detailed geocoordinate data and have already demonstrated powerful use of the Google Maps API, it would be possible to incorporate location details surrounding Citi Bike start and stop locations. There is potential for such data to be gathered automatically using API's such as Google's. Having this data would provide further insight into some of the reasons some bike share locations are more popular than others. Such data could even help Citi Bike predict changes in station demand based on changing surroundings and help determine where new stations should be installed.\n",
    "- ***Special Events:*** Similar to the previous idea, merging other public data based on geophysical coordinates and timeline could introduce other external factors such as the effects of parades, public concerts, festivals, and other events on ride activity for a given day or week. This would help identify/predict abnormal activity in this and future data sets. Additionally, it would provide insight to Citi Bike as to how to better plan and prepare for such events to boost rental count and increase trip duration.\n",
    "- ***GPS Enabled Bike Computers:*** Though not influenced by the data we have at hand, adding bicycle tracking hardware to each Citi Bike rental would provide substantial value to future data sets. Adding GPS tracking would enable Citi Bike to track specific routes followed by clients and could even aid NYC planners with transportation projects. Having route information means that true distance covered would be available, an attribute that would have far more meaning than our *LinearDistance* attribute. Incorporating GPS tracking with bike speed would provide insights into individual rider activity. For example, just because a rider's trip duration was 6 hours doesn't mean they actively rode for that amount of time. It is far more likely such a rider would have stopped for an extended period of time at least once during this period of time. Adding GPS and speed data would alleviate these existing gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptional Work\n",
    "Our team spent a substantial amount of time completing this assignment (50+ total man hours). Some of the features we would consider exceptional work include:\n",
    "- The shear volume of data alone was a challenge. Our original Citi Bike data was split across 8 files which we had to further split into 13 files due to Github file size restrictions. In total, our total record count consisted of 5562293 records, producing computational resource challenges on our personal computer hardware.\n",
    "- We chose to merge historical weather data with the pre-existing Citi Bike data, such that our set was comprised of data sourced from two independent entities. When merging all data, it would often take several hours to load the data alone.\n",
    "- We were very thorough in our data quality descriptions to ensure that no improper assumptions were made; this endeavor proved to be far more demanding than we had anticipated and proved to be a bottle-neck for our visualization creation and descriptive statistics.\n",
    "- Extensive effort was made to generate diversity in our visualizations and to incorporate interactivity where possible. This was a true learning experience as none of our previous classes have required significant use of the Python programming language.\n",
    "- Our use of the Google Maps API allowed us to view the data in ways that would have otherwise been impossible given our time constraints. Even with the additional configuration requirements for running the Google API and gmaps module, we managed to render our data over Google Maps and to gather further insights into why some stations portrayed more activity than others."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
